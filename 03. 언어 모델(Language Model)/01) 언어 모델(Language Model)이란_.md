언어 모델을 만드는 방법
- **통계를 이용한 방법** : SLM
- **인공 신경망을 이용한 방법** : ex) GPT, BERT
- 성능 : 인공 신경망을 이용한 방법 >> 통계를 이용한 방법

# 1. 언어 모델(Language Model)
- 언어 모델 : **단어 시퀀스에 확률을 할당**하는 일 : 가장 자연스러운 단어 시퀀스를 찾아내는 모델
   - **이전 단어들이 주어졌을 때 다음 단어를 예측**
   - 주어진 양쪽의 단어들로부터 가운데 비어있는 단어를 예측 : BERT
- 언어 모델링(Language Modeling) : 주어진 단어들로부터 아직 모르는 단어를 예측하는 작업

# 2. 단어 시퀀스의 확률 할당
#### a. 기계 번역(Machine Translation) 
*P(나는 버스를 탔다) > P(나는 버스를 태운다)*  
: 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단

#### b. 오타 교정(Spell Correction)
선생님이 교실로 부리나케  
*P(달려갔다) > P(잘려갔다)*  
: 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단

#### c. 음성인식 (Speech Recognition) 
*P(나는 메롱을 먹는다.) < P(나는 메론을 먹는다)** 
: 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단

언어 모델은 확률을 통해 **보다 적절한 문장을 판단**

# 3. 주어진 이전 단어들로부터 다음 단어 예측하기
#### A. 단어 시퀀스 확률
하나의 단어를 *w*, 단어 시퀀스를 대문자 *W*라고 한다면, n개의 단어가 등장하는 단어 시퀀스 *W*의 확률   
![image](https://user-images.githubusercontent.com/57162812/148984401-efcf2693-25b4-44b0-9701-95a733af6588.png)

#### B. 다음 단어 등장 확률
n-1개의 단어가 나열된 상태에서 n번쨰 단어의 확률  
![image](https://user-images.githubusercontent.com/57162812/148984479-458d00b0-574d-4a98-bf05-6a4a0058e053.png)

전체 단어 시퀀스 *W*의 확률은 모든 단어가 예측되고 나서야 알 수 있으므로 단어 시퀀스의 확률은 다음과 같다.  
![image](https://user-images.githubusercontent.com/57162812/148984637-c9bc8d6d-546d-4b9e-8d63-02ba4e34e946.png)

# 4. 언어 모델의 간단한 직관
**비행기를 타려고 공항에 갔는데 지각을 하는 바람에 비행기를 [?]** 
사람은 '놓쳤다'라고 예상할 수 있다. 우리 지식에 기반하여 가장 나올 확률이 높은 단어이기 때문이다.

기게라면? 앞에 어떤 단어들이 나왔는지 고려하여 후보가 될 수 있는 여러 단어들에 대해서 등장 확률을 예측해보고 가장 높은 확률을 가진 단어 선택

# 5. 검색 엔지에서의 언어 모델의 예
![image](https://user-images.githubusercontent.com/57162812/148985320-1c169376-b917-4fdf-8468-c7ebf9accdb1.png)
