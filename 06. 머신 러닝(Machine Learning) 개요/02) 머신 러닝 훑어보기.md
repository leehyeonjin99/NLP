# 1. 머신 러닝 모델의 평가

![image](https://user-images.githubusercontent.com/57162812/149282559-b025f650-8da6-4cff-8d84-0150e02151e1.png)

데이터=훈련용(학습 목적)+검증용(모델의 성능 조정 목적)+테스트용(모델의 성능 평가 목적)

검증용 데이터 : 모델이 훈련 데이터에 **과적합**이 되고 있는지 판단/하이퍼파라미터의 조정
- 하이퍼파라미터(초매개변수) : 모델의 성능에 영향을 주는 사람이 값을 지정하는 변수
- 매개변수 : 가중치와 편향, 학습을 하는 동안 값이 계속해서 변하는 수

훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 **튜닝(tuning)** 한다. 검증용 데이터에 대해서 높은 정확도를 얻도록 하이퍼파라미터의 값을 바꿔보는 것이다. 이렇게 튜닝하는 과정에서 모델은 검증용 데이터의 정확도를 높이는 방향으로 점차적으로 수정된다. 

# 2. 분류(Classification)와 회귀(Regression)
#### 1) 이진 분류 문제(Binary Classification)
주어진 입력에 대해서 두 개의 선택지 중 하나의 답을 선택  
ex) 종합 시험 성적표를 보고 최종적으로 합격, 불합격을 판단하는 문제

#### 2) 다중 클래스 분류(Multi-class Classification)
주어진 입력에 대해서 세 개 이상의 선택지 중에서 답을 선택  
ex) 서점 직원이 일을 하는데 과학, 영어, IT, 학습지, 만화라는 레이블이 붙어있는 5개의 책장이 있다. 새 책이 입고되면, 이 책을 다섯 개의 책장 중에서 맞는 분야를 판단하는 문제

#### 3) 회귀 문제(Regression)
어떠한 연속적인 값의 범위 내에서 예측값이 나오는 경우  
ex) 역과의 거리, 인구 밀도, 방의 개수 등을 입력하면 부동산 가격을 예측하는 문제, 시계열 데이터를 이용한 주가 예측, 생산량 예측, 지수 예측

# 3. 지도 학습과 비지도 학습
#### 1) 지도 학습(Supervised Learning)
레이블(Label)이라는 정답과 함께 학습  

#### 2) 비지도 학습(Unsupervies Learning)
별도의 레이블 없이 학습

#### 3) 자기지도 학습(Self-Supervised Learning, SSL)
레이블이 없는 데이터가 주어지면, 모델이 학습을 위해서 스스로 데이터로부터 레이블을 만들어서 학습  
ex) 워드 임제딩 알고리즘 : Word2Vec, 언어 모델 학습 방법 : BERT

# 4. 샘플(Sample)과 특성(Feature)
많은 머신 러닝 문제가 1개 이상의 독립 변수 x를 가지고 종속 변수 y를 예측하는 문제  
독립 변수 x의 행렬을 x라고 하였을 때, 독립 변수의 개수가 n개이고 데이터의 개수가 m인 행렬 X

![image](https://user-images.githubusercontent.com/57162812/149284880-d5869dde-c98d-4d54-82c2-d51700cd3947.png)


샘플 : 머신 러닝에서는 하나의 데이터, 행렬 관점에서는 하나의 행
특성 : 종속 변수 y를 예측하기 위한 각각의 독립변수 x

# 5. 혼동 행렬(Confusion Matrix)
|-|예측 참|예측 거짓|
|:---:|:---:|:---:|
|실제 참|TP|FN|
|실제 거짓|FP|TN|

- **True Positive(TP)** : 실제 True인 정답을 True라고 예측(정답)
- **False Positive(RP)** : 실제 False인 정답을 True라고 예측(오답)
- **False Negative(FN)** : 실제 True인 정답을 False라고 예측(오답)
- **True Negative(TN)** : 실제 False인 정답을 False라고 예측(정답)

#### 1) 정밀도(Precision)
모델이 True라고 분류한 것 중에서 실제 True인 것의 비율  
![image](https://user-images.githubusercontent.com/57162812/149285612-0e7d8ced-9403-4002-adc5-68599044ae03.png)

#### 2) 재현율(Recall)
실제 True인 것 중에서 모델이 True라고 예측한 것의 비율  
![image](https://user-images.githubusercontent.com/57162812/149285682-33a8ccce-c9b3-46d1-ad34-3df58c36517c.png)

#### 3) 정확도(Accuracy)
전체 예측한 데이터 중에서 정답을 맞춘 것에 대한 비율  
![image](https://user-images.githubusercontent.com/57162812/149285815-8bd3b275-da4f-4a07-b40e-31cdb2cd10dc.png)

# 6. 과적합(Overfitting)과 과소 적합(Underfitting)
**과적합** : 훈련 데이터를 과하게 학습한 경우
- 훈련 데이터에 대한 오차가 낮지만, 테스트 데이터에 대해서 오차가 크다.

![image](https://user-images.githubusercontent.com/57162812/149286100-8aee0270-852c-400e-84e8-2516f8873ba0.png)

y축 : 오차(loss), x축 : 에포크(epoch)-전체 훈련 데이터에 대한 훈련 횟수

**과소적합** : 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태

<해결 방안>
- 드롭 아웃
- 조기 종료

- Step 1. 주어진 데이터를 훈련 데이터, 검증 데이터, 테스트 데이터로 나눈다. 가령, 6:2:2 비율로 나눌 수 있다.
- Step 2. 훈련 데이터로 모델을 학습한다. (에포크 +1)
- Step 3. 검증 데이터로 모델을 평가하여 검증 데이터에 대한 정확도와 오차(loss)를 계산한다.
- Step 4. 검증 데이터의 오차가 증가하였다면 과적합 징후이므로 학습 종료 후 Step 5로 이동, 아니라면 Step 2.로 재이동한다.
- Step 5. 모델의 학습이 종료되었으니 테스트 데이터로 모델을 평가한다.
