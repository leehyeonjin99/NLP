{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7544dcac",
   "metadata": {},
   "source": [
    "각 문장(또는 문서)은 서로 길이가 다를 수 있다. 그런데 기계는 길이가 전부 동일한 문서들에 대해서는 하나의 행렬로 보고, 한꺼번에 묶어서 처리할 수 있다. 즉, 병렬 연산을 위해서 여러 문장의 길이를 임의로 동일하게 맞춰주는 작업이 필요할 떄가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a978b53",
   "metadata": {},
   "source": [
    "# 1. Numpy로 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7d87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b12505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sentences=[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58f6f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "encoded=tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88137f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 : 7\n"
     ]
    }
   ],
   "source": [
    "max_len=max(len(item) for item in encoded)\n",
    "print('최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f6b43",
   "metadata": {},
   "source": [
    "모든 문장의 길이를 max_len으로 맞추자. 가상의 단어 'PAD'가 있다고 가정하고, 이 단어는 0번 단어라고 정의한다. 길이가 max_len보다 짧은 문장에는 숫자 0을 채워서 길이를 max_len으로 맞춰준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8cb04ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in encoded:\n",
    "    while len(sentence)<max_len:\n",
    "        sentence.append(0)\n",
    "\n",
    "padded_np=np.array(encoded)\n",
    "padded_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5b7c3",
   "metadata": {},
   "source": [
    "기계는 이들을 하나의 행렬로 보고, 병렬 처리를 할 수 있다. 또한, 0번 단어는 사실 아무런 의미도 없는 단어이기 떄문에 자연어 처리하는 과정에서 기계는 0번 단어를 무시하게 된다.\n",
    "\n",
    "- 패딩(padding) : 데이터에 특정 값을 채워서 데이터의 크기(shape)를 조정\n",
    "- **제로 패딩(zero padding)** : 숫자 0을 사용한 패딩 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c408e5a",
   "metadata": {},
   "source": [
    "# 2. 케라스 전처리 도구로 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7859442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69c34fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "encoded=tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c3954d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  1,  5],\n",
       "       [ 0,  0,  0,  0,  1,  8,  5],\n",
       "       [ 0,  0,  0,  0,  1,  3,  5],\n",
       "       [ 0,  0,  0,  0,  0,  9,  2],\n",
       "       [ 0,  0,  0,  2,  4,  3,  2],\n",
       "       [ 0,  0,  0,  0,  0,  3,  2],\n",
       "       [ 0,  0,  0,  0,  1,  4,  6],\n",
       "       [ 0,  0,  0,  0,  1,  4,  6],\n",
       "       [ 0,  0,  0,  0,  1,  4,  2],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 0,  0,  0,  1, 12,  3, 13]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded=pad_sequences(encoded)\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aed6b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded=pad_sequences(encoded, padding='post')\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0930c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(padded==padded_np).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c22b5",
   "metadata": {},
   "source": [
    "실제로는 꼭 가장 긴 문서의 길이를 기준으로 해야하는 것은 아니다. 가령, 모든 문서의 평균 길이가 20인데 문서 1개의 길이가 5,000이라고 해서 굳이 모든 문서의 길이를 5,000으로 패딩할 필요는 없을 수 있다. max_len의 인자로 정수를 주면, 해당 정수로 모든 문서의 길이를 동일하게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d2cca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0],\n",
       "       [ 3,  2,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0],\n",
       "       [ 3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded=pad_sequences(encoded, padding='post', maxlen=5)\n",
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39303c6e",
   "metadata": {},
   "source": [
    "두번째 문장 : [7, 7, 3, 2, 10, 1, 11] → [3, 2, 10, 1, 11]\n",
    "앞의 단어가 아니라 뒤의 단어가 삭제되도록 하고싶다면 truncating이라는 인자를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb5ac0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0],\n",
       "       [ 3,  2,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10],\n",
       "       [ 1, 12,  3, 13,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded=pad_sequences(encoded, padding='post', maxlen=5, truncating='post')\n",
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f6932",
   "metadata": {},
   "source": [
    "pad_sequences의 value 인자로 0이 아닌 숫자로 패딩이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa121a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5, 14, 14, 14, 14, 14],\n",
       "       [ 1,  8,  5, 14, 14, 14, 14],\n",
       "       [ 1,  3,  5, 14, 14, 14, 14],\n",
       "       [ 9,  2, 14, 14, 14, 14, 14],\n",
       "       [ 2,  4,  3,  2, 14, 14, 14],\n",
       "       [ 3,  2, 14, 14, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14, 14, 14],\n",
       "       [ 1,  4,  2, 14, 14, 14, 14],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13, 14, 14, 14]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded=pad_sequences(encoded, padding='post', value=len(tokenizer.word_index)+1)\n",
    "padded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
